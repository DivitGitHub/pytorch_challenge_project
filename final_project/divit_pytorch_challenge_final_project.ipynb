{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "This is my solution for the pytorch challenge project.\n",
    "\n",
    "In this project, I'll train an image classifier to recognize different species of flowers. We'll be using <a href=\"http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\">this</a> dataset of 102 flower categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print(\"Cuda is available. Training on GPU...\")\n",
    "else:\n",
    "    print(\"Cuda is not available. Training on CPU...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "The dataset I'll be using can be downloaded <a href=\"https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\">here</a>. As you can see in the files, the dataset already provided us with a training and validation set.\n",
    "\n",
    "I'll be using a pre-trained network (resnet152) so we'll need to normalize the means and standard deviations of the images to what the network expects which is trained on ImageNet dataset. For the means, it's ```[0.485, 0.456, 0.406]``` and for the standard deviations ```[0.229, 0.224, 0.225]```, calculated from the ImageNet images. These values will shift each color channel to be centered at 0 and range from -1 to 1. In addition, our input data has to be of ```224x224``` pixels required by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our dataset dir\n",
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "# Transforms for the training and validation sets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "validate_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "validate_data = datasets.ImageFolder(valid_dir, transform=validate_transforms)\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our neutral network and classifier\n",
    "I decided to pick resnet152 as their CNN seems suited for our use-case.\nI've also tried training with densenet201 and densenet161 networks but resnet152 gave me the best validate and test accuracy\n",
    "\n",
    "You can learn more about it <a href=\"https://arxiv.org/abs/1512.03385\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Pre-trained model\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "# Freeze the parameters in the conv layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# construct a new classifier for fc layer\n",
    "classifier = nn.Sequential(nn.Linear(2048, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(p=0.25),\n",
    "                           nn.Linear(512, 102))\n",
    "\n",
    "# set our classifier to the fc layer\n",
    "model.fc = classifier\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=8, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and saving the network\n",
    "We'll be saving our network(state_dict) everytime when our validation loss reaches a new minimum while it's training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 70\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in validate_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    # update our learning rate if it's reaches a condition set by scheduler\n",
    "    scheduler.step(valid_loss)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(validate_loader.dataset)\n",
    "\n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_divit_pytorch_challenge.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "I'll be using https://github.com/GabrielePicco/deep-learning-flower-identifier class methods to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "def calc_accuracy(model, input_image_size, use_google_testset=False, testset_path=None, batch_size=32,\n",
    "                  norm_mean=[0.485, 0.456, 0.406], norm_std=[0.229, 0.224, 0.225]):\n",
    "    \"\"\"\n",
    "    Calculate the mean accuracy of the model on the test test\n",
    "    :param use_google_testset: If true use the testset derived from google image\n",
    "    :param testset_path: If None, use a default testset (missing image from the Udacity dataset,\n",
    "    downloaded from here: http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz)\n",
    "    :param batch_size:\n",
    "    :param model:\n",
    "    :param input_image_size:\n",
    "    :param norm_mean:\n",
    "    :param norm_std:\n",
    "    :return: the mean accuracy\n",
    "    \"\"\"\n",
    "    if use_google_testset:\n",
    "        testset_path = \"./google_test_data\"\n",
    "        url = 'https://www.dropbox.com/s/3zmf1kq58o909rq/google_test_data.zip?dl=1'\n",
    "        download_test_set(testset_path, url)\n",
    "    if testset_path is None:\n",
    "        testset_path = \"./flower_data_orginal_test\"\n",
    "        url = 'https://www.dropbox.com/s/da6ye9genbsdzbq/flower_data_original_test.zip?dl=1'\n",
    "        download_test_set(testset_path, url)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        batch_accuracy = []\n",
    "        torch.manual_seed(33)\n",
    "        torch.cuda.manual_seed(33)\n",
    "        np.random.seed(33)\n",
    "        random.seed(33)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        datatransform = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                            transforms.Resize(input_image_size + 32),\n",
    "                                            transforms.CenterCrop(input_image_size),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(norm_mean, norm_std)])\n",
    "        image_dataset = datasets.ImageFolder(testset_path, transform=datatransform)\n",
    "        dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=_init_fn)\n",
    "        for idx, (inputs, labels) in enumerate(dataloader):\n",
    "            if device == 'cuda':\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model.forward(inputs)\n",
    "            _, predicted = outputs.max(dim=1)\n",
    "            equals = predicted == labels.data\n",
    "            print(\"Batch accuracy (Size {}): {}\".format(batch_size, equals.float().mean()))\n",
    "            batch_accuracy.append(equals.float().mean().cpu().numpy())\n",
    "        mean_acc = np.mean(batch_accuracy)\n",
    "        print(\"Mean accuracy: {}\".format(mean_acc))\n",
    "    return mean_acc\n",
    "\n",
    "def download_test_set(default_path, url):\n",
    "    \"\"\"\n",
    "    Download a testset containing approximately 10 images for every flower category.\n",
    "    The images were download with the download_testset script and hosted on dropbox.\n",
    "    :param default_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not os.path.exists(default_path):\n",
    "        print(\"Downloading the dataset from: {}\".format(url))\n",
    "        tmp_zip_path = \"./tmp.zip\"\n",
    "        urllib.request.urlretrieve(url, tmp_zip_path, download_progress)\n",
    "        with zipfile.ZipFile(tmp_zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(default_path)\n",
    "        os.remove(tmp_zip_path)\n",
    "\n",
    "def download_progress(blocknum, blocksize, totalsize):\n",
    "    \"\"\"\n",
    "    Show download progress\n",
    "    :param blocknum:\n",
    "    :param blocksize:\n",
    "    :param totalsize:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    readsofar = blocknum * blocksize\n",
    "    if totalsize > 0:\n",
    "        percent = readsofar * 1e2 / totalsize\n",
    "        s = \"\\r%5.1f%% %*d / %d\" % (\n",
    "            percent, len(str(totalsize)), readsofar, totalsize)\n",
    "        sys.stderr.write(s)\n",
    "        if readsofar >= totalsize: # near the end\n",
    "            sys.stderr.write(\"\\n\")\n",
    "    else: # total size is unknown\n",
    "        sys.stderr.write(\"read %d\\n\" % (readsofar,))\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    It makes determinations applied transforms\n",
    "    :param worker_id:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    np.random.seed(77 + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "calc_accuracy(model, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label mapping\n",
    "This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers. The json file can be found in this project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save checkpoint\n",
    "Here we could save more information about our model if we need to continue to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the additional state\n",
    "model.class_to_idx = train_data.class_to_idx\n",
    "\n",
    "checkpoint = {'class_to_idx' : model.class_to_idx,\n",
    "              'optimizer_state_dict' : optimizer.state_dict(),\n",
    "              'cat_to_name' : cat_to_name,\n",
    "              'classifier' : classifier,\n",
    "              'epoch' : n_epochs,\n",
    "              'state_dict' : model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'pytorch_final_divit_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading checkpoint\n",
    "Here is how I would load my model if I need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_my_model(filePath):\n",
    "    checkpoint = torch.load(filePath)\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    model.fc = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
